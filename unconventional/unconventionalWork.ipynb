{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "equal-eight",
   "metadata": {},
   "source": [
    "**Matthew Ueckermannn**\n",
    "## PDF Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dressed-narrative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the         2640\n",
       ".           2323\n",
       "of          1580\n",
       "to          1384\n",
       "and         1174\n",
       "a            977\n",
       "in           694\n",
       "is           612\n",
       "for          524\n",
       "that         507\n",
       "be           431\n",
       "data         407\n",
       "The          361\n",
       "are          349\n",
       "with         337\n",
       "as           307\n",
       "students     259\n",
       "can          257\n",
       "this         247\n",
       "course       233\n",
       "it           222\n",
       "or           221\n",
       "on           210\n",
       "an           190\n",
       "their        182\n",
       "was          176\n",
       "Data         171\n",
       "by           171\n",
       "not          168\n",
       "I            155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "doc = fitz.open('dissertation.pdf')\n",
    "text = \"\".join(page.get_text(\"text\") for page in doc)\n",
    "words = pd.Series(text.split())\n",
    "words.value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "former-blame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fall</td>\n",
       "      <td>2020 Fall Term</td>\n",
       "      <td></td>\n",
       "      <td>2021 Fall Term</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First Day of Classes</td>\n",
       "      <td>Tue</td>\n",
       "      <td>September 1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>August 31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labor Day - Classes Will Meet</td>\n",
       "      <td>Mon</td>\n",
       "      <td>September 7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labor Day - Classes Suspended</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mon</td>\n",
       "      <td>September 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last day to add or drop courses</td>\n",
       "      <td>Tue</td>\n",
       "      <td>September 15</td>\n",
       "      <td>Tue</td>\n",
       "      <td>September 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Summer Session - 10 week - classes begin</td>\n",
       "      <td>Mon</td>\n",
       "      <td>June 7</td>\n",
       "      <td>Mon</td>\n",
       "      <td>June 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Last day to add or drop courses</td>\n",
       "      <td>Wed</td>\n",
       "      <td>June 16</td>\n",
       "      <td>Wed</td>\n",
       "      <td>June 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Last day to change registration or withdraw fr...</td>\n",
       "      <td>Thur</td>\n",
       "      <td>July 15</td>\n",
       "      <td>Thur</td>\n",
       "      <td>July 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Final Exams</td>\n",
       "      <td>Fri</td>\n",
       "      <td>August 13</td>\n",
       "      <td>Fri</td>\n",
       "      <td>August 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Deadline for 10-week grades to be posted to UDSIS</td>\n",
       "      <td>Tue</td>\n",
       "      <td>August 17</td>\n",
       "      <td>Tue</td>\n",
       "      <td>August 16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0               1  \\\n",
       "0                                                Fall  2020 Fall Term   \n",
       "1                                First Day of Classes             Tue   \n",
       "2                       Labor Day - Classes Will Meet             Mon   \n",
       "3                       Labor Day - Classes Suspended                   \n",
       "4                     Last day to add or drop courses             Tue   \n",
       "..                                                ...             ...   \n",
       "70           Summer Session - 10 week - classes begin             Mon   \n",
       "71                    Last day to add or drop courses             Wed   \n",
       "72  Last day to change registration or withdraw fr...            Thur   \n",
       "73                                        Final Exams             Fri   \n",
       "74  Deadline for 10-week grades to be posted to UDSIS             Tue   \n",
       "\n",
       "               2               3             4  \n",
       "0                 2021 Fall Term                \n",
       "1    September 1             Tue     August 31  \n",
       "2    September 7                                \n",
       "3                            Mon   September 6  \n",
       "4   September 15             Tue  September 14  \n",
       "..           ...             ...           ...  \n",
       "70        June 7             Mon        June 6  \n",
       "71       June 16             Wed       June 15  \n",
       "72       July 15            Thur       July 14  \n",
       "73     August 13             Fri     August 12  \n",
       "74     August 17             Tue     August 16  \n",
       "\n",
       "[75 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import camelot\n",
    "tables = camelot.read_pdf('calendar.pdf')\n",
    "df = tables[0].df\n",
    "df # seems to have worked well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-opinion",
   "metadata": {},
   "source": [
    "### My example\n",
    "\n",
    "I am interested in the distribution of words from my VLE report from CHEG345 (Junior lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "threaded-listing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the            533\n",
       "of             284\n",
       "in             233\n",
       "and            162\n",
       "for            139\n",
       "to             127\n",
       "pressure       109\n",
       "is              96\n",
       "that            78\n",
       "methyl          69\n",
       "a               65\n",
       "was             65\n",
       "this            65\n",
       "be              64\n",
       "acetate         60\n",
       "at              55\n",
       "mole            53\n",
       "±               53\n",
       "as              52\n",
       "activity        51\n",
       "infinite        50\n",
       "can             49\n",
       "are             49\n",
       "dilution        47\n",
       "temperature     46\n",
       "methanol        46\n",
       "The             41\n",
       "by              40\n",
       "fraction        40\n",
       "with            39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('F1-VLE-Final.pdf')\n",
    "text = \"\".join(page.get_text(\"text\") for page in doc)\n",
    "words = pd.Series(text.split())\n",
    "words.value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-court",
   "metadata": {},
   "source": [
    "I was curious if VLE would make it (vapor liquid equilibrium) but I guess not. The gap betewen methyl and acetate is also interesting as they should be used together as \"methyl acetate\" as I doubt we ever called methanol methyl alcohol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-protein",
   "metadata": {},
   "source": [
    "## Reddit Image Transcriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interpreted-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a User Agent to avoid being blocked\n",
    "import requests\n",
    "import pprint\n",
    "import pytesseract\n",
    "import re\n",
    "import io\n",
    "from PIL import Image\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "renewable-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get(\"https://www.reddit.com/r/comics/.json\", headers = {'User-agent': 'your bot 0.1'}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sonic-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\matth\\desktop\\cisc367\\cisc367_dir\\venv\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Flags not at the start of the expression 'https://i.redd.it/([' (truncated)\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "all_text = \"\"\n",
    "all_titles = []\n",
    "all_sentiment = []\n",
    "\n",
    "for post in data['data']['children']:\n",
    "    \n",
    "    title = post['data']['title']\n",
    "    url = post['data']['url']\n",
    "    \n",
    "    # Regex adapted from: https://www.geeksforgeeks.org/how-to-validate-image-file-extension-using-regular-expression/\n",
    "    regex = 'https://i.redd.it/([^\\\\s]+(\\\\.(?i)(jpe?g|png|gif|bmp))$)'\n",
    "    pattern = re.compile(regex)\n",
    "    \n",
    "    if(re.search(pattern,url)):\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(io.BytesIO(response.content))\n",
    "        text = pytesseract.image_to_string(img) #from spot checking, not super accurate but still impressive\n",
    "        all_text += text\n",
    "        blob = TextBlob(text)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        \n",
    "        all_titles.append(title)\n",
    "        all_sentiment.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "operating-melbourne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at the most frequent words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "that     6\n",
       "my       6\n",
       "on       6\n",
       "and      6\n",
       "to       8\n",
       "i        9\n",
       "you     12\n",
       "s       12\n",
       "a       14\n",
       "the     15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(all_text)\n",
    "print(\"Looking at the most frequent words:\")\n",
    "pd.Series(blob.word_counts).sort_values().tail(10) # Not super interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hybrid-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A breakdown of the sentiment of a sample posts on this sub is given by:\n",
      "count    23.000000\n",
      "mean      0.118248\n",
      "std       0.316118\n",
      "min      -0.431818\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.227827\n",
      "max       0.988281\n",
      "dtype: float64\n",
      "The average tends to indicate that the sentiment is slightly positive; however, it is likely that most posts are just neutral\n"
     ]
    }
   ],
   "source": [
    "print(\"A breakdown of the sentiment of a sample posts on this sub is given by:\")\n",
    "s = pd.Series(data=all_sentiment)\n",
    "print(s.describe())\n",
    "print(\"The average tends to indicate that the sentiment is slightly positive; however, it is likely that most posts are just neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-radio",
   "metadata": {},
   "source": [
    "## Trying Another Sub\n",
    "\n",
    "Was going to do r/chemicalengineering, but decided a sub with more pictures with text would be interesting. So lets try r/funnysigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "automated-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get(\"https://www.reddit.com/r/funnysigns/.json\", headers = {'User-agent': 'your bot 0.1'}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "usual-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \"\"\n",
    "all_titles = []\n",
    "all_sentiment = []\n",
    "\n",
    "for post in data['data']['children']:\n",
    "    \n",
    "    title = post['data']['title']\n",
    "    url = post['data']['url']\n",
    "    \n",
    "    # Regex adapted from: https://www.geeksforgeeks.org/how-to-validate-image-file-extension-using-regular-expression/\n",
    "    regex = 'https://i.redd.it/([^\\\\s]+(\\\\.(?i)(jpe?g|png|gif|bmp))$)'\n",
    "    pattern = re.compile(regex)\n",
    "    \n",
    "    if(re.search(pattern,url)):\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(io.BytesIO(response.content))\n",
    "        text = pytesseract.image_to_string(img) #from spot checking, not super accurate but still impressive\n",
    "        all_text += text\n",
    "        blob = TextBlob(text)\n",
    "        sentiment = blob.sentiment.polarity\n",
    "        \n",
    "        all_titles.append(title)\n",
    "        all_sentiment.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "social-removal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at the most frequent words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stay     4\n",
       "ae       5\n",
       "‘        5\n",
       "to       5\n",
       "ee       5\n",
       "i        5\n",
       "you      6\n",
       "7        7\n",
       "—        8\n",
       "a       12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(all_text)\n",
    "print(\"Looking at the most frequent words:\")\n",
    "pd.Series(blob.word_counts).sort_values().tail(10) # Not super interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ordered-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A breakdown of the sentiment of a sample posts on this sub is given by:\n",
      "count    23.000000\n",
      "mean      0.006262\n",
      "std       0.131497\n",
      "min      -0.400000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.000000\n",
      "max       0.272000\n",
      "dtype: float64\n",
      "The average indicates that there is no bias in sentiment; however, most posts are just neutral\n"
     ]
    }
   ],
   "source": [
    "print(\"A breakdown of the sentiment of a sample posts on this sub is given by:\")\n",
    "s = pd.Series(data=all_sentiment)\n",
    "print(s.describe())\n",
    "print(\"The average indicates that there is no bias in sentiment; however, most posts are just neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-lying",
   "metadata": {},
   "source": [
    "## Face Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chicken-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comic-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traning with the default classifiers\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abandoned-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Ueckermann_headshot.JPG')\n",
    "smallImg = cv2.resize(img, (750,1000), interpolation=cv2.INTER_AREA) # my go to headshot\n",
    "gray = cv2.cvtColor(smallImg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    smallImg = cv2.rectangle(smallImg,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = smallImg[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('img',smallImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-transcription",
   "metadata": {},
   "source": [
    "Grabs my nostrails as eyes as well, but at least it identifies the rest correctly...\n",
    "\n",
    "What about a group of people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "earlier-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('main_street.JPG')\n",
    "smallImg = cv2.resize(img, (750,1000), interpolation=cv2.INTER_AREA) # my go to headshot\n",
    "gray = cv2.cvtColor(smallImg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    smallImg = cv2.rectangle(smallImg,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = smallImg[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('img',smallImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-determination",
   "metadata": {},
   "source": [
    "Misses Nicholas and is pretty bad with the eyes, but hey I guess 3/4 faces isnt horrible..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-paintball",
   "metadata": {},
   "source": [
    "What if we change the classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "historic-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "left_eye_cascade = cv2.CascadeClassifier('haarcascade_lefteye_2splits.xml')\n",
    "right_eye_cascade = cv2.CascadeClassifier('haarcascade_righteye_2splits.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "original-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Ueckermann_headshot.JPG')\n",
    "smallImg = cv2.resize(img, (750,1000), interpolation=cv2.INTER_AREA) # my go to headshot\n",
    "gray = cv2.cvtColor(smallImg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    smallImg = cv2.rectangle(smallImg,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = smallImg[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('img',smallImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-costa",
   "metadata": {},
   "source": [
    "Huh,just identifies the other nostrial now... not much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dried-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('main_street.JPG')\n",
    "smallImg = cv2.resize(img, (750,1000), interpolation=cv2.INTER_AREA) # my go to headshot\n",
    "gray = cv2.cvtColor(smallImg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    smallImg = cv2.rectangle(smallImg,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = smallImg[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('img',smallImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-chorus",
   "metadata": {},
   "source": [
    "Looks like this just idenitifies Chandlers left eye twice, probably need to train for the lighting/angles/zoom."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
